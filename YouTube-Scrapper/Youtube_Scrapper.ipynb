{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas import DataFrame\n",
    "from json import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Get the html by get method\n",
    "r = requests.get(url)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "#soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_script_tags = soup.findAll('script')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def script_tag_to_json(tags: list) -> dict:\n",
    "    for tag in reversed(tags):\n",
    "        text: str = tag.text\n",
    "        if 'ytInitialData = {\"responseContext\"' in text:\n",
    "            return loads(text[20:-1])\n",
    "\n",
    "    raise ValueError('Required script tag not found in the given tags.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = script_tag_to_json(all_script_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contents_dict(data):\n",
    "    return data['contents']['twoColumnBrowseResultsRenderer']['tabs'][1]['tabRenderer']['content']['richGridRenderer']['contents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.youtube.com/watch?v=PI1obes98Zc',\n",
       " 'https://www.youtube.com/watch?v=16fUsD0M1-I',\n",
       " 'https://www.youtube.com/watch?v=S0RySN5arvk',\n",
       " 'https://www.youtube.com/watch?v=HzBhwxMrt8A',\n",
       " 'https://www.youtube.com/watch?v=60_B3haKADw']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_videoUrl(data:dict, n: int = 5):\n",
    "    contents = get_contents_dict(data)\n",
    "\n",
    "    if n > 30:\n",
    "        raise ValueError('Max Limit is 30.')\n",
    "\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append('https://www.youtube.com/watch?v=' +\n",
    "                      contents[i]['richItemRenderer']['content']['videoRenderer']['videoId'])\n",
    "\n",
    "    return result\n",
    "\n",
    "print(len(get_videoUrl(data)))\n",
    "get_videoUrl(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://i.ytimg.com/vi/PI1obes98Zc/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLCmDshrYrFfclOymZmlDi79xYzKMA',\n",
       " 'https://i.ytimg.com/vi/16fUsD0M1-I/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLDSdB3RrY_91M4wFdU8WorfjHTrGA',\n",
       " 'https://i.ytimg.com/vi/S0RySN5arvk/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLAMklN-udq5wIHmAyDjx4yd4HxvGg',\n",
       " 'https://i.ytimg.com/vi/HzBhwxMrt8A/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLDhGQyUAc5A_0sapaGDI_uDE_GNrg',\n",
       " 'https://i.ytimg.com/vi/60_B3haKADw/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLCz1LFTtDzJooWDMArb4Qfh74PC_w']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_thumbnails(data: dict, n: int = 5):\n",
    "    contents = get_contents_dict(data)\n",
    "\n",
    "    if n > 30:\n",
    "        raise ValueError('Max Limit is 30.')\n",
    "\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append(contents[i]['richItemRenderer']['content']['videoRenderer']['thumbnail']['thumbnails'][-1]['url'])\n",
    "\n",
    "    return result\n",
    "\n",
    "print(len(get_thumbnails(data)))\n",
    "get_thumbnails(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Write a python program to extract the title of the first five videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['How to score 95%+ in class 10th? Complete year Powerful Strategy!!',\n",
       " 'Last 4 Days Left For SST Exam || How To Manage to Score 80/80 in Boards || Class-10th',\n",
       " 'Benefits of Choosing Commerce After 10th | Commerce क्यों लेना चाहिए? | CBSE | ICSE | State Boards',\n",
       " 'Complete 𝗖𝗔𝗥𝗕𝗢𝗡 𝗔𝗡𝗗 𝗜𝗧𝗦 𝗖𝗢𝗠𝗣𝗢𝗨𝗡𝗗𝗦 in 90 Minutes | Class 10th Board Exam',\n",
       " 'Complete 𝗠𝗘𝗧𝗔𝗟𝗦 & 𝗡𝗢𝗡 𝗠𝗘𝗧𝗔𝗟𝗦  in 120 Minutes | Class 10th Board Exam']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_title(data: dict, n:int = 5):\n",
    "    contents = get_contents_dict(data)\n",
    "\n",
    "    if n > 30:\n",
    "        raise ValueError('Max Limit is 30.')\n",
    "\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append(contents[i]['richItemRenderer']['content']['videoRenderer']['title']['runs'][-1]['text'])\n",
    "\n",
    "    return result\n",
    "\n",
    "print(len(get_title(data)))\n",
    "get_title(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['77,699 views',\n",
       " '65,861 views',\n",
       " '25,296 views',\n",
       " '40,608 views',\n",
       " '22,109 views']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_viwes(data: dict, n: int = 5):\n",
    "    contents = get_contents_dict(data)\n",
    "\n",
    "    if n > 30:\n",
    "        raise ValueError('Max Limit is 30.')\n",
    "\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append((contents[i]['richItemRenderer']['content']['videoRenderer']['viewCountText']['simpleText']\n",
    "                      [:-6]+' views'))\n",
    "\n",
    "    return result\n",
    "\n",
    "print(len(get_viwes(data)))\n",
    "get_viwes(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2 days ago', '3 days ago', '7 days ago', '9 days ago', '9 days ago']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_time_of_posting(data: dict, n: int = 5):\n",
    "    contents = get_contents_dict(data)\n",
    "\n",
    "    if n > 30:\n",
    "        raise ValueError('Max Limit is 30.')\n",
    "\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append(contents[i]['richItemRenderer']['content']['videoRenderer']['publishedTimeText']['simpleText'])\n",
    "\n",
    "    return result\n",
    "\n",
    "print(len(get_time_of_posting(data)))\n",
    "get_time_of_posting(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating function to get date from relative time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "def get_absolute_date(relative_time):\n",
    "    absolute_time = []\n",
    "    for i in relative_time:\n",
    "        if i.find('minute')>0:\n",
    "            minutes = int(i.split(\" \")[0])\n",
    "            tm_absolute = datetime.now() - pd.Timedelta(minutes=minutes)\n",
    "            dt_string = tm_absolute.strftime(\"%d %b %Y\")\n",
    "            absolute_time.append(dt_string)        \n",
    "        elif i.find('hours')>0:\n",
    "            hours = int(i.split(\" \")[0])\n",
    "            tm_absolute = datetime.now() - pd.Timedelta(hours=hours)\n",
    "            dt_string = tm_absolute.strftime(\"%d %b %Y\")\n",
    "            absolute_time.append(dt_string)\n",
    "        elif i.find('day')>0:\n",
    "            days = int(i.split(\" \")[0])\n",
    "            tm_absolute = datetime.now() - pd.Timedelta(days=days)\n",
    "            dt_string = tm_absolute.strftime(\"%d %b %Y\")\n",
    "            absolute_time.append(dt_string)\n",
    "        elif i.find('week')>0:\n",
    "            weeks = int(i.split(\" \")[0])\n",
    "            tm_absolute = datetime.now() - pd.Timedelta(weeks=weeks)\n",
    "            dt_string = tm_absolute.strftime(\"%d %b %Y\")\n",
    "            absolute_time.append(dt_string)\n",
    "        elif i.find('month')>0:\n",
    "            months = int(i.split(\" \")[0])\n",
    "            tm_absolute = datetime.now() - relativedelta(months=months)\n",
    "            dt_string = tm_absolute.strftime(\"%d %b %Y\")\n",
    "            absolute_time.append(dt_string)\n",
    "        elif i.find('year')>0:\n",
    "            years = int(i.split(\" \")[0])\n",
    "            tm_absolute = datetime.now() - relativedelta(years=years)\n",
    "            dt_string = tm_absolute.strftime(\"%d %b %Y\")\n",
    "            absolute_time.append(dt_string)\n",
    "\n",
    "    return absolute_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11 Mar 2023', '10 Mar 2023', '06 Mar 2023', '04 Mar 2023', '04 Mar 2023']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_date = get_absolute_date(get_time_of_posting(data))\n",
    "abs_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Save all the data scraped in the above questions in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_video_details(data: dict, n: int):\n",
    "    thumbnails = get_thumbnails(data, n)\n",
    "    time_of_posting = get_time_of_posting(data, n)\n",
    "    titles = get_title(data, n)\n",
    "    video_urls = get_videoUrl(data, n)\n",
    "    viwes=get_viwes(data, n)\n",
    "\n",
    "    main_data = list(zip(titles, video_urls, thumbnails, viwes, time_of_posting, abs_date))\n",
    "    \n",
    "    df = DataFrame.from_dict(main_data)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            0: 'Title',\n",
    "            1: 'Video Url',\n",
    "            2: 'Thumbnail',\n",
    "            3: 'Views',\n",
    "            4: 'Time of Posting',\n",
    "            5: 'Absolute Date'\n",
    "        }, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data = get_channel_video_details(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data.to_csv('PW-Foundation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
